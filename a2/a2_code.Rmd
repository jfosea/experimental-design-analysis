---
geometry: margin=1.5cm
output:
  pdf_document: default
  html_document: default
---
\begin{center}
    \LARGE
    \textbf{STAT 425 - Statistical Design and Analysis of Experiments}
 
    \vspace{0.3cm}
    \LARGE
    \textbf{Assignment 2}
    
    \large
    \noindent\makebox[\linewidth]{\rule{20cm}{0.8pt}}
    \textbf{Name:} Jana Osea \\
    \textbf{Student ID:} 30016679
    \noindent\makebox[\linewidth]{\rule{20cm}{0.8pt}}
\end{center}

```{r, include=FALSE}
library(ggplot2)
library(mosaic)
library(dplyr)
library(EnvStats)
library(lawstat)
library(DescTools)
setwd("C:/Users/surfacepro/Desktop/425_a2/datasets")
```


1. The phenomenon of road rage has received much media attention in recent years. Is a driver's propensity
to engage in road rage related to his or her income? Researchers in Mississippi State University attempted to
answer this question by conducting a survey of a representative sample of 1,000 U.S. adult driver1
. Based on
how often each driver engaged in certain road rage behaviors (ie., making obscene gestures at, tailgating, and
thinking about physically hurting another driver), a road rage score was assigned. (Higher scores indicate
a greater pattern of road rage behavior.) The drivers were also grouped by annual income: under \$30,000,
between \$30,000 and \$60,000, and over \$60,000. The data was subjected to an analysis, producing the
given statistics in the document.

    (a) Find the value of $\overline{X}$. (Hint: Are the sample sizes the same?)
    
    
        \textbf{Solution:} The overall average can be calculated by the following where $w_k$ is the sample weight of the $k-th$ treatment.
        \begin{align*}
            \overline{X} &= \sum_{k=1}^{3} w_k \overline{X}_{k} \\
             &= \frac{379}{1038} \times 4.6 + \frac{392}{1038} \times 5.08 + \frac{267}{1038} \times 5.15 \\
             &= 4.9227
        \end{align*}
            
    (b) Provide the ANOVA table. 
    
    
        \textbf{Solution:} The values can be obtained by the following:
        \begin{align*}
            SST &= 8417.447 \\ \\
            SSB &= \sum_{k=1} ^3 n_k\overline{X}_k^2 - n\overline{X}^2 \\
            &= \left( 379 \times 4.6^2 + 392 \times 5.08^2 + 267 \times 5.515^2 \right) - 1038 \times 4.9227^2 \\
            &= 62.961 \\ \\
            SSE &= SST - SSB \\
            &= 8417.447 - 62.961 \\
            &= 8354.486
        \end{align*}
        
        \begin{align*}
            df_{between} &= k - 1 \\
            &= 3 - 1 \\
            &= 2 \\ \\
            df_{within} &= n - k \\
            &= 1038 - 3 \\
            &= 1035 \\ \\
            df_{total} &= n - 1 \\
            &= 1038 -1 \\ \\
            MSB &= \frac{SSB}{df_{between}} \\
            &= \frac{62.961}{2} \\
            &= 31.481 \\ \\
            MSW &= \frac{SSW}{df_{within}} \\
            &= \frac{8354.486}{1035} \\
            &= 8.072 \\ \\
            F_{obs} &= \frac{\frac{SSB}{df_{between}}}{\frac{SSW}{df_{within}}} \\
            &= \frac{\frac{62.961}{2}}{\frac{8354.486}{1035}} \\
            &= \frac{31.481}{8.072} \\ \\
            P-value &= P(F_{2,1035} > F_{obs}) \\
            &= 0.0205
        \end{align*}

                
        | Source  | DF   | SS       | MS     | F     | P-value |
        |---------|------|----------|--------|-------|---------|
        | Between |   2  |  62.961  | 31.481 | 3.900 |  0.0205 |
        | Within  | 1035 | 8354.486 |  8.072 |       |         |
        | Total   | 1037 | 8417.447 |        |       |         |

      

    (c) What are the conditions under which an ANOVA analysis is conducted? State the two conditions in
    the context of the data collected.
    
        \textbf{Solution:} There are 2 conditions that must be met. 
        \begin{enumerate}
          \item Normality: The response variable $X_{ij}$ is Normally distributed. As well, the residual terms $e_{ij}$ are independent random variables that are Normally distributed with a mean of 0, or $E(e_{ij})=0$
          \item Homoscedasticity: The variance in the response variable (road range values) are the same across all groups (income groups).
        \end{enumerate}
    
    
    (d) Assuming the conditions stated in (c) hold true, test the hypothesis that there is no difference in the
    road rage score across the three income classes. What is your decision? (Use $\alpha = 0.05$). 
    
        \textbf{Solution:} We wish to test the following hypothesis:
        
        \begin{align*}
            &H_0: \mu_{<30000} = \mu_{30000-60000} = \mu_{>60000} \\
            &H_a: \text{at least one } \mu \text{ is not the same for the } k= 3 \text{ populations}
        \end{align*}
        
        Using the ANOVA table above, we get that
        
        \begin{align*}
            F_{obs} &= 3.9 \\
            P-value &= P(F_{2, 1035} > F_{obs}) = 0.0205
        \end{align*}
        
        Based on this data, the $P-value=P(F_{2, 1035} > F_{obs}) = 0.0205$ which is less than 0.05. One can conclude that the three populations are not equal with respect to the response variable (road range values). The mean value of the response variable is different for at least one of these $k=3$ populations.
        
    (e) Interpret the meaning of the P-value in (d) in the context of the data.
    
        \textbf{Solution:} Based on this data, the mean the road range value of at least one income group is not the same; there exists a 0.0205 probability of another experiment producing stronger statistical evidence against the null hypothesis than the current evidence.
        
        
    (f) If the null hypothesis in (d) is not rejected, construct a 95% confidence interval for $\mu$ - the mean
    road rage score of all individuals. IF the null hypothesis in (d) is rejected, construct a 95% confidence
    interval estimates for (i) $\mu_{<30}$, (ii) $\mu_{30-60}$ and (iii) $\mu_{>60}$.
    Ensure you interpret the meaning of these intervals in the context of the data.
    
        \textbf{Solution}: Null hypothesis is rejected and so we will be using the following formula where $k$ is the different income groups.
        \begin{align*}
            \overline{X_k} \pm t_{0.025, n_{k}-1} \frac{MSE}{\sqrt{n_k}}
        \end{align*}
        Using R to perform the calculation, we obtain the following confidence intervals 
      
        ```{r}
        4.6 + c(-1,1)*abs(qt(0.05/2, 379-1))*(sqrt(8.072)/sqrt(379))
        5.08 + c(-1,1)*abs(qt(0.05/2, 392-1))*(sqrt(8.072)/sqrt(392))
        5.15 + c(-1,1)*abs(qt(0.05/2, 267-1))*(sqrt(8.072)/sqrt(267))
        ```
        
        \begin{enumerate}
            \item Based on this data, the $95\%$ confidence interval for $\mu_{<30}$ is between  4.313046 and 4.886954. This means the if we perform this experiment many times, $95\%$ of the road range averages calculated will be captured by this interval.
            \item Based on this data, the $95\%$ confidence interval for $\mu_{30-60}$ is between 4.797875 and 5.362125. This means the if we perform this experiment many times, $95\%$ of the road range averages calculated will be captured by this interval.
            \item Based on this data, the $95\%$ confidence interval for $\mu_{>60}$ is between  4.807655 and 5.492345. This means the if we perform this experiment many times, $95\%$ of the road range averages calculated will be captured by this interval.
        \end{enumerate}
        
        \newpage
        
2. Refer to the data in Chapter 3, end of chapter question 3.15.

    (a) Create boxplots of these data with ggplot. What do these boxplots tell you about the association
    between the number of weeks a car is rented and type of car?
    
        \textbf{Solution:} Based on our data, the boxplots below seem to show that the variances between each sample are the same because the inter quartile ranges look around the same size.
    
        ```{r, echo=F}
        p2 <- read.csv("p2.csv")
        type <- c(rep("Subcompact", 10), rep("Compact", 10), rep("Midsize", 10), rep("Full Size", 10))
        period <- c(p2[,1], p2[,2], p2[,3], p2[,4])
        p2 <- data.frame(type, period)
        ggplot(data=p2, aes(x = type, y = period)) + geom_boxplot(col="black", fill="white") + xlab("Type of Car") + ylab("Number of Periods") + coord_flip()
                ```
    
    (b) Compute SST, SSB, and SSW and summarize your findings in the form of an ANOVA table.
    
        \textbf{Solution:} Using the following R code, we can produce parts of the ANOVA table.
        
        ```{r}
        summary(aov(period~type, data=p2))
        ```
            
          Completing the table using the fact the $df_{Total} = n - 1$ and $SST = SSW + SSB$

          | Source    | DF | SS     | MS    | F    | P-value |
          |-----------|----|--------|-------|------|---------|
          | Type      | 3  | 16.67  | 5.558 | 1.11 | 0.358   |
          | Residuals | 36 | 180.30 | 5.008 |      |         |
          | Total     | 39 | 196.97 |       |      |         |
        
    (c) From (b): Does the data indicate that the type of car rented affects the length of the rental contract?
    State the appropriate statistical hypothesis, provide the value of the test statistic, and compute/provide
    the P-value. What can you infer from these data? Carry out the test at $\alpha = 0.05$. In addition to
    computing its value, ensure you interpret the meaning of the P-value.
    
        \textbf{Solution:} We are testing the following test of hypothesis:
        \begin{align*}
            &H_0: \mu_{Subcompact} = \mu_{Midsize} = \mu_{Full Size} = \mu_{Compact} \\
            &H_a: \text{at least one } \mu \text{ is not the same for the } k= 4 \text{ populations}
        \end{align*}
        
        From the ANOVA table above we get the following results
        
        \begin{align*}
            F_{obs} &= 1.11 \\
            P-value &= P(F_{3, 26} > F_{obs}) = 0.358
        \end{align*}
        
        Based on this data, the $P-value=P(F_{3, 26} > F_{obs}) = 0.358$ which is greater than 0.05. One can conclude that the four populations are equal with respect to the response variable (rental periods). The mean value of the response variable is the same for all these $k=4$ populations. There exists a 0.358 probability of another experiment producing stronger statistical evidence against the null hypothesis.
        
    (d) Analyze the residuals from this experiment. Are the one-way model assumptions satisfied? Explain.
    
        \textbf{Solution:} There are 2 conditions that must be met as outline in 1(c).
        
        1. Normal distribution of residuals
        
        ```{r, echo=F}
        a <- aov(period~type, data=p2)
        p2$ei_terms <- residuals(a)
        ggplot(data=p2, aes(sample=ei_terms)) + stat_qq(col="blue", size = 1) + stat_qqline(col="red") + ggtitle("Normal Probability Plot of the Residuals")
        shapiro.test(p2$ei_terms)
        ```

        From the qq plot above, the residuals seem to be generally normally distributed. However, the tails seem to deviate too much. In order to check if the residuals are indeed are normally distributed, we check the Shapiro-Wilk test. We get that the p-value=0.1386 > 0.05.
        
                
        2. Homoscedasticity
        
        ```{r, echo=F}
        b <- favstats(period~type, data=p2)
        p2$fits <- c(rep(b$mean[1], 10), rep(b$mean[2], 10), rep(b$mean[3], 10), rep(b$mean[4], 10)) 
        ggplot(data=p2, aes(x = fits, y = ei_terms)) + geom_point(size=2, col="blue") + xlab("Fitted Values") + ylab("Residuals/Error Terms") + ggtitle("Plot of Fits to Residuals") + geom_hline(yintercept=0, linetype="dashed", color="red")
        ```
        The residual plot shows no distinct pattern. As well, the points are balanced around the horizontal line equal to 0. Thus, the variance between the groups are indeed true. 
        
    
    (e) Consider your comments from part (a): Carry out the appropriate test to that will determine if the
    variation in these data is the same for the four different types of cars
    
        \textbf{Solution:} In order to check if the variances are the same for all populations, we perform an Levene's test by the one-way ANOVA of $|X_{ij} - \tilde{X_i}|$ for $i=$ Subcompact,Midisize, Full size, and Compact. We have the following hypothesis:
        
        \begin{align*}
        &H_0: \sigma_{Subcompact} = \sigma_{Midsize} = \sigma_{Full Size} = \sigma_{Compact} = \sigma_{Common} \\
        &H_a: \text{at least one } \sigma \text{ is different for all }k=4 \text{ populations}
        \end{align*}
        
        ```{r}
        a <- favstats(period~type, data=p2)$median
        p2$median <- c(rep(a[4],10), rep(a[1],10), rep(a[3],10), rep(a[2],10))
        p2$absdiff <- abs(p2$period - p2$median)
        summary(aov(absdiff~type, data=p2))
        ```
        
        From the above, we get that
        \begin{align*}
              &F_{obs} = 0.067 \\
              &P-value = P(F_{3, 36} > F_{obs}) = 0.977
        \end{align*}
        
        Based on the data, the $P-value = P(F_{3, 36} > F_{obs}) = 0.977$ which is greater than 0.05 and so we do not reject the null hypothesis. The standard deviation in the period of rental for each type of car is the same; there exists a 0.977 probability of another experiment producing stronger statistical evidence against the null hypothesis.
        
        
    (f) Using 1000 iterations or replications, carry out a condition-free statistical test to these data. In your
    summary of your result(s), ensure you indicate (i) the observed result and (ii) your empirical P-value. (iii)
    Are you results consistent with your findings in part (c)?
          
        \textbf{Solution:} We produce the following histogram:
          
        ```{r}
        set.seed(1)
        demopermtest1000.df = do(1000) * rsquared(lm(period ~ shuffle(type), data=p2))
        obsrsquared = rsquared(lm(period~type, data=p2))
        ggplot(data=demopermtest1000.df, aes(x = rsquared)) + geom_histogram(col="black", fill="white", binwidth=0.05) + xlab("Values of r-squared") + ylab("Count") + ggtitle("Outcomes of 1000 Permutation Tests") + geom_vline(xintercept=obsrsquared, linetype="dashed", col="red")
        ```
          
          (i) Using the do function from the Mosaic package, we perform 1000 iterations of the test to these data. Based on the data, we will super impose the $r^2 = 0.08465541$ value to the histogram plot. We observe that our observed $r^2$ is quite commonly observed.
          
          (ii) The empirical p-value can be calculated through the following:
            ```{r}
            howmany = sum(demopermtest1000.df$rsquared > obsrsquared)
            emp_P_value = (howmany/1000)
            emp_P_value
            ```
          
            From the above, we get that the empirical p-value = 0.349 This means that 349 tests out of 1000 of permutation tests produced a value of $r^2$ that exceeded 0.0847.
          
          (iii) Finally, this result is consisten with the results from (c). The p-value from (c) is $p-value_c=0.358$ and the p-value from (f) is $p-value_f=0.384$. These two values are close to each other. As well, the $r^2$ value from the data is quite common from the histogram above.
          
\newpage

3.  The U.S. Army Corps of Engineers collected data on the DDT levels of three different species of fish:
channel catfish, largemouth bass, and smallmouth buffalofish. The DDT levels were measured in PPM (parts
per million) on 144 captured fish. The data is found in the FISHDDT.csv file in the directory:

    (a) Provide a boxplot and commentary of the DDT levels comparing the distribution of DDT levels
    amongst the three different types of fish. If necessary, provide the test statistic and P-value of the statistical test that compares the variation in the DDT levels amongst the three different species of fish.
    
        \textbf{Solution:} 
        ```{r}
        p3 <- read.csv("p3.csv")
        p3 <- p3[order(p3$SPECIES),]
        ggplot(data=p3, aes(x = SPECIES, y = DDT)) + geom_boxplot(col="black", fill="white") + xlab("Species of Fish") + ylab("DDT Level in ppm") + coord_flip()
        ```
        From the boxplot above, it is difficult to make any conclusion concerning the variance between the populations to be the same or not. Hence, we perform a Levene's test using a one-way ANOVA on the $|X_{ij} - \tilde{X_i}|$ for $i=$ Channel Cat Fish, Small Mouth Buff, and Large Mouth Buff. We have the following hypothesis where $X_{ij}$ is the DDT levels in ppm for the specified fish and $\tilde{X_i}$ is the median for that species of fish:
        
        \begin{align*}
        &H_0: \sigma_{Channel Cat Fish} = \sigma_{Small Mouth Buff} = \sigma_{Large Mouth Buff} = \sigma_{Common} \\
        &H_a: \text{at least one } \sigma \text{ is different for all }k=3 \text{ species}
        \end{align*}
        
        ```{r}
        a <- favstats(DDT~SPECIES, data=p3)$median
        p3$median <- c(rep(a[1],96), rep(a[2],12), rep(a[3],36))
        p3$absdiff <- abs(p3$DDT - p3$median)
        summary(aov(absdiff~SPECIES, data=p3))
        ```
        From the above, we get that
        \begin{align*}
              &F_{obs} = 0.917  \\
              &P-value = P(F_{2, 141} > F_{obs}) = 0.402
        \end{align*}
        
        Based on this data, the $P-value = P(F_{2, 141} > F_{obs}) = 0.402$ which is greater than 0.05 and so we do not reject the null hypothesis. The standard deviation in the DDT levels of each species of fish is the same; there exists a 0.402 probability of another experiment producing stronger statistical evidence against the null hypothesis.
        
    (b) Does this data indicate that one species of fish has higher DDT levels than any other species, on
    average? Use $\alpha = 0.05$.
    
        \textbf{Solution:} We wish to perform an ANOVA test. For the sake of the of procedure, we will assume that the residual normality condition has been met. And so, we test the following hypothesis
        
        \begin{align*}
            &H_0: \mu_{Channel Cat Fish} = \mu_{Small Mouth Buff} = \mu_{Large Mouth Buff}\\
            &H_a: \text{at least one of the k=3 species is not the same}
        \end{align*}
        
        Using R to perform the test:
        ```{r}
        summary(aov(DDT~SPECIES, data=p3))
        ```
        From which, we get
        \begin{align*}
            &F_{obs} = 1.22 \\
            P-value &= P(F_{2,141} > F_{obs}) =  0.3 
        \end{align*}
        
        Based on this data, the $P-value = P(F_{2,141} > F_{obs}) =  0.3 $ which is greater than 0.05 and so we do not reject the null hypothesis. One can conclude that all the species are the same in terms of the mean DDT levels in ppm. There exists a 0.3 probability of another experiment producing stronger statistical evidence against the null hypothesis.
        
        
    (c) If the null hypothesis in (b) is not rejected, construct a 95% confidence interval for $\mu$ - the DDT level
    in the fish. If the null hypothesis in (b) is rejected, construct a 95% confidence interval estimates for
    
        (i)$\mu_{Channel Cat Fish}$ (ii) $\mu_{Small Mouth Buff}$ (iii) $\mu_{Large Mouth Buff}$
        
        \textbf{Solution:} Frome (b) we do not reject the null hypothesis. Hence, we use the following formula for the 95% confidence interval of the mean DDT levels:
        
        \begin{align*}
              \overline{X} \pm t_{0.025, n-1} \sqrt{\frac{MSE}{n}}
        \end{align*}

        Using, R to compute the intervals we get:
        
        ```{r}
        mse <- 9649  
        mean(p3$DDT)+ c(-1,1)*abs(qt(0.05/2, 144-1)*(sqrt(mse/144)))

        ```
        Based on this data, the $95\%$ confidence interval for $\mu$ is between  8.1742 and 40.5358. This means the if we perform this experiment many times, $95\%$ of the DDT levels in ppm for this species calculated will be captured by this interval.
        
        
    (d) With an experiment error rate of 0.05, carry out the appropriate multiple-comparison method to that
    will identify which species has the highest DDT level.
    
        \textbf{Solution:} We will perform a Bonferroni multiple comparison method with an error rate=0.05 using the R code below:

        ```{r}
        PostHocTest(aov(DDT ~ SPECIES, data=p3), method="bonferroni", conf.level=0.95)
        ```
        We will summarize the results in a table below:
        
        $\begin{array}{cccc}
        \text{Lower Bound}   & \mu_{i} - \mu_{j}   & \text{Upper Bound}  & \text{Finding} \\
        \hline
        -104.79            & \mu_{LargeMouthBass} - \mu_{ChannelCatFish} &    40.95            & \mu_{LargeMouthBass} = \mu_{ChannelCatFish} \\
        -71.65              & \mu_{SmallMouthBuff} - \mu_{ChannelCatFIsh} &    21.38            & \mu_{SmallMouthBuff} = \mu_{ChannelCatFIsh} \\
        -72.55              & \mu_{SmallMoutBuff} - \mu_{LargeMouthBass} &    86.12            & \mu_{SmallMoutBuff} = \mu_{LargeMouthBass}
        \end{array}$
                
        From the summary above, we see can conclude that:
        \begin{align*}
             \mu_{LargeMouthBass} = \mu_{ChannelCatFish} = \mu_{SmallMouthBuff}
        \end{align*}
        
        Based on the data, there is no specific specific species with the highest DDT levels in ppm. This is consistent with our result in (b).
        
\newpage

4. Can a secondary task, like a word association task, improve your performance when you are fatigued?
Data from the a study appearing in Human Factors resulted from researchers using a driving simulation
experiment. Each of n = 40 students was randomly assigned to one of four groups, then each student was
to simulate driving long-distance (the same distance) in a driving simulator. Students assigned to Group 1
performed a verbal task continuously (continuous verbal). Students assigned to a Group 2 performed the
verbal task during only at the end of their drive (end verbal); students assigned to Group 3 did not perform
the task at all (no verbal communication), and students assigned to Group 4 listed to a certain radio program
while driving the long-distance (radio show condition). \newline \newline
At the end of the trial, each student was asked to recall billboards they they saw along the way. The response
variable measured was the percentage of billboards recalled by each student-driver. These data can be found
in the FATIGUE.csv file found in the same data file directory as indicated in Question 3. Read these data
into R/R Studio and answer the following questions:

    (a) Suppose the response variable in this case is Normally distributed, and the standard deviation in the
    percentage of billboards recalled is the same for the four groups, can you conclude from these data
    that there is no difference in the mean percentage recall for student-drivers in the four groups?
    
        \textbf{Solution:} Assuming the condtions are met. We perform an ANOVA test with the following hypothesis:
        \begin{align*}
            &H_0: \mu_{continuous verbal} = \mu_{End Verbal} = \mu_{No Verbal} =  \mu_{Radio} \\
            &H_a: \text{at least one } \mu \text{ is not the same for the } k= 4 \text{ groups}
        \end{align*}
        
        Using R, we get that:
        ```{r}
        p4 <- read.csv("p4.csv")
        summary(aov(RECALL~GROUP, data=p4))
        ```
        
        From the ANOVA table above we get the following results:
        
        \begin{align*}
            F_{obs} &= 5.388 \\
            P-value &= P(F_{3, 36} > F_{obs}) = 0.00362
        \end{align*}
        
        Based on this data, the $P-value = P(F_{3, 36} > F_{obs}) = 0.00362$ which is less than 0.05 and so we reject the null hypothesis. One can conclude that the three populations are equal with respect to the response variable (percent billboards recalled). The mean value of the percent billboards recalled is the different for at least one of these $k=4$ groups There exists a 0.00362 probability of another experiment producing stronger statistical evidence against the null hypothesis.
        
    (b) Do these data indicate that the distribution of the percentage of billboards recalled is the same for
    the four groups? Carry out the appropriate statistical test, showing all relevant work. What can you
    infer?
        
        \textbf{Solution:} In order to test for the similar distributions, we perform a Kruskal-Wallis test with the following hypothesis:
        
        \begin{align*}
            &H_0: \text{The distribution of the percent billboards recalled are the same for all k=4 groups} \\
            &H_a: \text{Not all k=4 groups are distributated the same}
          \end{align*}
        
        Using R to perform the test:
        ```{r}
        kruskal.test(RECALL ~ GROUP, data=p4)
        ```
        From which, we get
        \begin{align*}
            &KW_{obs} = 12.846 \\
            P-value &= P(\chi^2_{2} > KW_{obs}) = 0.004983
        \end{align*}
        
        Based on this data, the $P-value = P(\chi^2_{2} > KW_{obs}) = 0.004983$ which is less than 0.05 and so we reject the null hypothesis. One can conclude that at least one group is not distributed the same in terms of the percent billboards recalled. There exists a 0.004983 probability of another experiment producing stronger statistical evidence against the null hypothesis.
        
        
    (c) Similar to Question 2(f), conduct a permutation test. Use 1000 iterations/replications. Ensure you
    provide (i) your code and (ii) your empirical P-value. What can you infer?
        
        \textbf{Solution:} We produce the following histogram:
          
        ```{r}
        set.seed(1)
        demopermtest1000.df = do(1000) * rsquared(lm(RECALL ~ shuffle(GROUP), data=p4))
        obsrsquared = rsquared(lm(RECALL~GROUP, data=p4))
        obsrsquared
        ggplot(data=demopermtest1000.df, aes(x = rsquared)) + geom_histogram(col="black", fill="white", binwidth=0.05) + xlab("Values of r-squared") + ylab("Count") + ggtitle("Outcomes of 1000 Permutation Tests") + geom_vline(xintercept=obsrsquared, linetype="dashed", col="red")
        ```
          
          (i) Using the do function from the Mosaic package, we perform 1000 iterations of the test to these data. Based on the data, we will super impose the $r^2 = 0.3098566$ value to the histogram plot. We observe that our observed $r^2$ is not that commonly observed.
          
          (ii) The empirical p-value can be calculated through the following:
            ```{r}
            howmany = sum(demopermtest1000.df$rsquared > obsrsquared)
            emp_P_value = (howmany/1000)
            emp_P_value
            ```
          
            From the above, we get that the empirical p-value = 0.002. This means that only 2 tests out of 1000 of permutation tests produced a value of $r^2$ that exceeded 0.3098566. This result is consistent with the results from (a). The p-value from (a) is $p-value_a=0.004683$ and the p-value from (c) is $p-value_c=0.002$. These two values are close to each other. As well, the $r^2$ value from the data is not that common from the histogram above.
          
    (d) Return to part (a): Given what you know about these data, carry out the appropriate multiplecomparison method to identify which treatment results in the "best" proportion of billboards remembered. Summarize your results.
        
        \textbf{Solution:} We will perforam a Tukey's Honestly Significant difference multiple comparison test:
        
        ```{r}
        PostHocTest(aov(RECALL ~ GROUP, data=p4), method="hsd", conf.level=0.95, ordered = TRUE)
        ```
        
        We can summarize the results using the table below:
        
        \begin{center}
        $\begin{array}{cccc}
        \text{Lower Bound}   & \mu_{i} - \mu_{j}   & \text{Upper Bound}  & \text{Finding} \\
        \hline
        -8.35            & \mu_{Radio} - \mu_{ContVerb} &    37.75            & \mu_{Radio} = \mu_{ContVerb} \\
        6.05              & \mu_{LateVerb} - \mu_{ContVerb} &    52.15            & \mu_{LateVerb} > \mu_{ContVerb}  \\
        6.54              & \mu_{NoVerb} - \mu_{ContVerb} &    52.65            &\mu_{NoVerb} > \mu_{ContVerb} \\
        -8.65              & \mu_{LateVerb} - \mu_{Radio} &    37.45            & \mu_{LateVerb} = \mu_{Radio} \\
        -8.15              & \mu_{Noverb} - \mu_{Radio} &   37.95            & \mu_{Noverb} = \mu_{Radio}  \\
        -22.55              & \mu_{NoVerb} - \mu_{LateVerb} &    23.55            & \mu_{NoVerb} = \mu_{LateVerb} \\
        \end{array}$
        \end{center}
                
        From the summary above, we see can conclude that:
        \begin{align*}
             \mu_{NoVerb} &= \mu_{LateVerb} > \mu_{ContVerb} = \mu_{Radio}; \\
             \mu_{Radio} &= \mu_{LateVerb}; \\
             \mu_{Radio} &= \mu_{NoVerb}
        \end{align*}
        
        Based on the data and the table above derived from the Bonferroni multiple comparison method, we get that no verbal communication and late verbal communication are the treatment methods that provide the "best" proportion of billboards recalled. It is hard to determine which method is better than the other since the mean difference is statistically the 0.
        
        
        
        
\newpage

5. Do television shows with violence and sex impair memory for commercials? Investigators publishing in
the Journal of Applied Psychology carried out an experiment where 324 subjects were randomly assigned to
one of three viewer groups. One group watched a television show with violent content code (or a V-rating);
the second group viewed a show with a six content code (or a S-rating), the third group watched a television
show that was rated as "general". Nine commercials were embedded into each television show. After viewing
the program, each subject was scored on their recall of the brand names from the nine commercials, with
scores ranging from 0 to 9. The data can be found in the TVADS.csv.
Does the data suggest that TV shows with violent content and sexual content impair memory for commercials?
For Question 5, I want a one-page report/summary. This summary should include:


    1. Visualizations of these data, along with appropriate commentary associated with each visualization.
    For example, why are you creating boxplots? What do the boxplots suggest?
    2. An application of two different statistical methods, each with their associated statistical hypotheses,
    computed values of test statistic and P-value.
    3. Should the null hypothesis be rejected, a deeper analysis into "why" the null hypothesis is rejected.
    That is, if the data do suggest that violent content and sexual content in television shows do impair
    memory for commercials, is the effect on the response variable the same for these two types of content?
    Do persons have better memory of commercials embedded in television shows with violent content or
    sexual content, or is their memory worse?
    
        \textbf{Solution:} Report found on next page.


\newpage

\begin{center}
    \Large
    \textbf{Do Television Shows With Violence and Sex Impair Memory for Commercials?} \\
    \normalsize
    By: Jana Osea
    \noindent\makebox[\linewidth]{\rule{20cm}{0.8pt}}
\end{center}

\begin{center} \Large\textbf{Introduction} \end{center}
\normalsize

Invetigators from the \textit{Journal of Applied Psychology} wanted to test whether TV shows with violent and sexual content impair memory for commercials. The study design description can be found on the last page of the assignment sheet. Our goal is to test whether there is a difference between all the different groups and if there exists a difference, we want to test what is the treatement increase memory scores.


\begin{center} \Large\textbf{Conditions} \end{center}
\normalsize

1. Equal Variance: In order to check for equal variance among each group, we will plot a boxplot as shown below. Since the interquartile ranges seem to be of the same size, we can conlcude that the condition of homoscedasticity has been met.

    ```{r, fig.width=7, fig.height=2.5, echo=F}
    p5 <- read.csv("p5.csv")
    p5$residuals <- residuals(lm(SCORE~GROUP, data=p5))
    b <- favstats(SCORE~GROUP, data=p5)$mean
    p5$fits <- c(rep(b[1], 108), rep(b[2], 108), rep(b[3], 108))
    ggplot(data=p5, aes(x = GROUP, y = SCORE)) + geom_boxplot(col="black", fill="white") + xlab("TV Show Rating") + ylab("Number of Commericals Remembered") + coord_flip()
    ```
    
2. Normality: Next, we must check the assumption of normality of the residuals

    ```{r, fig.width=7, fig.height=3.5, echo=FALSE}
    # conditions check
    # 1. normality use CLT
    ggplot(data=p5, aes(sample=residuals)) + stat_qq(col="blue", size = 1) + stat_qqline(col="red") + ggtitle("Normal Probability Plot of the Residuals")
    shapiro.test(p5$residuals) 
    ```

    From the results of the Shapiro-Wilk test ($p-value \approx 0$) and the qq plot above, it is clear that the data residuals do not follow an approximately normal distribution. Hence, we will use a non-parametric method to analyze the data instead.


\begin{center} \Large\textbf{Analysis} \end{center}
\normalsize 

We will perform two tests of hypothesis:

1. First will perform a Kruskal Wallis test with the following hypothesis:
    \begin{align*}
                &H_0: \text{The distribution of the commericals recall score are the same for all k=3 groups} \\ 
                &H_a: \text{Not all k=3 groups are distributated the same}
    \end{align*}

    Using R we get the following:
    
    ```{r, echo=FALSE}
    kruskal.test(SCORE~GROUP, data=p5)
    ```
    
    From which, we get the following test statistic and p-value
    
    \begin{align*}
      &KW_{obs} =37.153 \\
      P-value &= P(\chi^2_{2} > KW_{obs}) = 8.556e-09
    \end{align*}
    
    Based on this data, the $P-value = P(\chi^2_{2} > KW_{obs}) = 8.556e-09$ which is less than 0.05 and so we reject the null hypothesis. One can conclude that at least one group is not distributed the same in terms of the commercials recalled score. There exists a approximately 0 probability of another experiment producing stronger statistical evidence against the null hypothesis.
    
2. Next, we will perform a permutation test with the following hypothesis:

    \begin{align*}
            &H_0: \mu_{Violent} = \mu_{Sex} = \mu_{Neutral} \\
            &H_a: \text{at least one } \mu \text{ is not the same for the } k= 3 \text{ treatment groups}
    \end{align*}

    Using R, we will perform a permutation test:
    ```{r}
    set.seed(1)
    demopermtest1000.df = do(1000) * rsquared(lm(SCORE ~ shuffle(GROUP), data=p5))
    obsrsquared = rsquared(lm(SCORE~GROUP, data=p5))
    howmany = sum(demopermtest1000.df$rsquared > obsrsquared)
    emp_P_value = (howmany/1000)
    c(emp_P_value, obsrsquared)
    ```
    ```{r, fig.width=7, fig.height=2.7, echo=FALSE}
    ggplot(data=demopermtest1000.df, aes(x = rsquared)) + geom_histogram(col="black", fill="white", binwidth=0.05) + xlab("Values of r-squared") + ylab("Count") + ggtitle("Outcomes of 1000 Permutation Tests") + geom_vline(xintercept=obsrsquared, linetype="dashed", col="red")
    ```
    
    From which we get that
    \begin{align*}
            &r^2_{observed} = 0.1130235 \\
            &P-value_{empirical} = 0
    \end{align*}
    
    From the above, we get that the empirical p-value = 0. This means that only approximately 0 tests out of 1000 of permutation tests produced a value of $r^2$ that exceeded 0.1130235. This is consistent with the results from the Kruskal-Wallis test above. Based on the data, one can conclude that there is a difference in the mean esponse variable (commercials recalled score) between the violent, sexual, and neutral TV show groups.
    
    
    
\begin{center} \Large\textbf{Further Analysis} \end{center}
\normalsize 

Since we rejected the global hypothesis that these groups are the same. We are not sure if we should treat the Neutral tv program group as control, so we will perform a Tukey's Honest Significant Different method using the R code below:

```{r}
TukeyHSD(SCORE ~ GROUP, ordered=T, conf.level=0.95, data=p5)
```

From which, we can derive the following table

\begin{center}    
$\begin{array}{cccc}
\text{Lower Bound}   & \mu_{i} - \mu_{j}   & \text{Upper Bound}  & \text{Finding} \\
\hline
-0.1858756            & \mu_{Violent} - \mu_{Sex} &    0.9266163            & \mu_{Violent} = \mu_{Sex} \\
0.8974578              & \mu_{Neutral} - \mu_{Sex} &    2.0099496            & \mu_{Neutral} > \mu_{Sex} \\
0.5270874              & \mu_{Neutral} - \mu_{Violent} &    1.6395793            & \mu_{Neutral} > \mu_{Violent} \\
\end{array}$
\end{center}

Based on the data, we can conclude the following:
\begin{align*}
  \mu_{Neutral} > \mu_{Violent} = \mu_{Sex}
\end{align*}

\begin{center} \Large\textbf{Conclusion} \end{center}
\normalsize 

Based on the data along with all the analysis, we conclude that there is a difference between the mean commercials recall score of the different TV groups with 95% confidence. Furthermore, the group with neutral TV ratings were able to retain the most commercial recall score compared to TV ratings with sex or violence. Interestingly, there is no statistical difference between violent and sexual TV watchers. To conclude, this brings light the fact that the content of TV shows have an impact on our memory and that perhaps TV viewers should be more aware of their TV watching endeavors.